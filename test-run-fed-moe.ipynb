{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5444824,"sourceType":"datasetVersion","datasetId":1424314}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install protobuf==3.20.3\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T13:09:50.846361Z","iopub.execute_input":"2025-12-03T13:09:50.846616Z","iopub.status.idle":"2025-12-03T13:09:54.530597Z","shell.execute_reply.started":"2025-12-03T13:09:50.846597Z","shell.execute_reply":"2025-12-03T13:09:54.529733Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.11/dist-packages (3.20.3)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModel, AutoTokenizer\nfrom datasets import load_dataset\nimport copy\nimport types\nimport weakref  # <--- NEW: Import weakref for non-registering parent reference\n# --- START: Data Utilities Imports ---\nimport os\nimport glob\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nimport math\n# --- END: Data Utilities Imports ---\n\nclass MoEFFN(nn.Module):\n    \"\"\"\n    Mixture-of-Experts Feed-Forward Network replacing the standard FFN in transformer layers.\n    Supports load balancing loss.\n    \"\"\"\n    def __init__(self, config, num_experts=8, top_k=2, load_balance_coeff=0.01):\n        super().__init__()\n        self.hidden_size = config.hidden_size\n        self.intermediate_size = config.intermediate_size\n        self.gate = nn.Linear(self.hidden_size, num_experts)\n        self.experts = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(self.hidden_size, self.intermediate_size),\n                nn.GELU(),\n                nn.Linear(self.intermediate_size, self.hidden_size)\n            ) for _ in range(num_experts)\n        ])\n        self.top_k = top_k\n        self.num_experts = num_experts\n        self.load_balance_coeff = load_balance_coeff\n\n    def forward(self, hidden_states):\n        batch_size, seq_len, hidden_size = hidden_states.shape\n        flat_hidden = hidden_states.reshape(-1, hidden_size)  # (b*s, d)\n        num_tokens = flat_hidden.shape[0]\n        gate_logits = self.gate(flat_hidden)  # (b*s, e)\n        gate_probs = torch.softmax(gate_logits, dim=-1)\n        topk_probs, topk_idx = gate_probs.topk(self.top_k, dim=-1)  # (b*s, k)\n        final_output = torch.zeros_like(flat_hidden)\n        balance_loss = torch.zeros((), device=hidden_states.device)\n        if self.training:\n            dispatch_fraction = torch.zeros(self.num_experts, device=hidden_states.device)\n            router_prob_mean = gate_probs.mean(dim=0)\n        for e in range(self.num_experts):\n            expert_mask = (topk_idx == e)\n            token_mask = expert_mask.any(dim=-1)\n            flat_token_indices = torch.nonzero(token_mask).squeeze(-1)\n            if flat_token_indices.numel() == 0:\n                continue\n            input_e = flat_hidden.index_select(0, flat_token_indices)\n            out_e = self.experts[e](input_e)\n            probs_for_e = (topk_probs * expert_mask.float()).sum(dim=-1)\n            weights = probs_for_e[token_mask]\n            weighted = out_e * weights.unsqueeze(-1)\n            final_output.index_add_(0, flat_token_indices, weighted)\n            if self.training:\n                dispatch_fraction[e] = token_mask.float().sum() / num_tokens\n        if self.training:\n            balance_loss = self.load_balance_coeff * self.num_experts * (dispatch_fraction * router_prob_mean).sum()\n        return final_output.reshape(batch_size, seq_len, hidden_size), balance_loss\n\nclass Projection(nn.Module):\n    \"\"\"\n    Lightweight MLP projection head for contrastive embeddings.\n    \"\"\"\n    def __init__(self, in_dim, hidden_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hidden_dim)\n        self.act = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, out_dim)\n\n    def forward(self, h):\n        return self.fc2(self.act(self.fc1(h)))\n\nclass FedMoECR(nn.Module):\n    \"\"\"\n    FedMoE-CR model: CodeBERT backbone with MoE layers and projection head.\n    \"\"\"\n    def __init__(self, num_experts=8, top_k=2, proj_dim=128, load_balance_coeff=0.01):\n        super().__init__()\n        self.encoder = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n        dim = self.encoder.config.hidden_size\n        self.projection = Projection(dim, dim * 4, proj_dim)\n        self.log_tau = nn.Parameter(torch.tensor(math.log(0.07)))\n        self.total_balance_loss = torch.tensor(0.0)  # Initialized as tensor; reset in compute_loss\n        # Replace two mid-layer FFN blocks with MoE\n        for i in [5, 8]:  # Layers 6 and 9 (0-indexed)\n            layer = self.encoder.encoder.layer[i]\n            # 1. Attach MoE FFN and Parent Reference\n            moe_ffn = MoEFFN(self.encoder.config, num_experts, top_k, load_balance_coeff)\n            layer.moe_ffn = moe_ffn\n            # CRITICAL FIX: Use weakref to store parent reference without module registration\n            layer.parent_model = weakref.ref(self)\n            # 2. Set up LayerNorm aliases (CodeBERT structure)\n            layer.layernorm_before = layer.attention.output.LayerNorm\n            layer.layernorm_after = layer.output.LayerNorm\n\n            def new_forward(layer_self, hidden_states, attention_mask=None, head_mask=None,\n                            encoder_hidden_states=None, encoder_attention_mask=None,\n                            past_key_value=None, output_attentions=False):\n                # 1. Self-Attention Block\n                self_attention_outputs = layer_self.attention(\n                    hidden_states, attention_mask, head_mask, output_attentions=output_attentions,\n                )\n                attention_output = self_attention_outputs[0]\n                outputs = self_attention_outputs[1:]\n                # No extra residual/LN here; attention_output is already post-residual + LN\n                normalized_attention_output = attention_output\n                # 3. MoE Feed-Forward Network\n                moe_output, moe_balance_loss = layer_self.moe_ffn(normalized_attention_output)\n                # 4. Second Residual Connection + LayerNorm (Post-MoE)\n                moe_output = layer_self.output.dropout(moe_output)\n                layer_output = layer_self.layernorm_after(moe_output + normalized_attention_output)\n                # 5. Accumulate Loss\n                if layer_self.training:\n                    # CRITICAL FIX: Dereference weakref and check if parent is alive\n                    parent = layer_self.parent_model()\n                    if parent is not None:\n                        parent.total_balance_loss += moe_balance_loss\n                outputs = (layer_output,) + outputs\n                return outputs\n\n            # 3. Bind the new forward method\n            layer.forward = types.MethodType(new_forward, layer)\n\n    def forward(self, inputs):\n        # No reset here; handled in compute_loss to accumulate across query/code forwards\n        outputs = self.encoder(**inputs)\n        h = outputs.last_hidden_state[:, 0]  # CLS token\n        z = self.projection(h)\n        z = F.normalize(z, dim=1)\n        return z\n\nclass CodeDataset(Dataset):\n    \"\"\"\n    Dataset for query-code pairs from CodeSearchNet.\n    Modified to take a Pandas DataFrame as input.\n    \"\"\"\n    def __init__(self, df):\n        self.queries = df['docstring'].tolist()\n        self.codes = df['code'].tolist()\n\n    def __len__(self):\n        return len(self.queries)\n\n    def __getitem__(self, idx):\n        return self.queries[idx], self.codes[idx]\n\ndef collate_fn(batch, tokenizer):\n    queries, codes = zip(*batch)\n    q_inputs = tokenizer(list(queries), padding=True, truncation=True, return_tensors='pt', max_length=128)\n    c_inputs = tokenizer(list(codes), padding=True, truncation=True, return_tensors='pt', max_length=512)\n    return q_inputs, c_inputs\n\ndef compute_loss(model, q_inputs, c_inputs, device):\n    q_inputs = {k: v.to(device) for k, v in q_inputs.items()}\n    c_inputs = {k: v.to(device) for k, v in c_inputs.items()}\n    if model.training:\n        model.total_balance_loss = torch.zeros((), device=device)\n    z_q = model(q_inputs)\n    z_c = model(c_inputs)\n    tau = model.log_tau.exp()\n    dots = torch.mm(z_q, z_c.T)\n    sim = dots / tau\n    labels = torch.arange(z_q.size(0)).to(device)\n    nce_loss = nn.CrossEntropyLoss()(sim, labels)\n    total_loss = nce_loss\n    if model.training:\n        total_loss += model.total_balance_loss\n    return total_loss\n\ndef apply_dp_gradients(model, clip_norm, noise_std, batch_size):\n    \"\"\"\n    Apply gradient clipping and noise for differential privacy.\n    Approximates DP by scaling noise appropriately (note: this is batch-level, not per-sample DP).\n    \"\"\"\n    params = [p for p in model.parameters() if p.grad is not None]\n    if len(params) == 0:\n        return\n    total_norm = torch.sqrt(sum(p.grad.norm(2)**2 for p in params))\n    if total_norm > clip_norm:\n        for p in params:\n            p.grad.detach().mul_(clip_norm / total_norm)\n    effective_std = noise_std * clip_norm / batch_size  # Scale for approximate DP\n    for p in params:\n        noise = torch.normal(\n            mean=0.0,\n            std=effective_std,\n            size=p.grad.shape,\n            device=p.grad.device,\n            dtype=p.grad.dtype\n        )\n        p.grad += noise\n\ndef local_update(model, dataloader, optimizer, device, local_steps, clip_norm, noise_std):\n    model.train()\n    for _ in range(local_steps):\n        for q_inputs, c_inputs in dataloader:\n            batch_size = q_inputs['input_ids'].shape[0]  # Get current batch size\n            optimizer.zero_grad()\n            loss = compute_loss(model, q_inputs, c_inputs, device)\n            loss.backward()\n            apply_dp_gradients(model, clip_norm, noise_std, batch_size)\n            optimizer.step()\n\ndef federated_aggregation(global_model, client_models, client_sizes):\n    total_size = sum(client_sizes)\n    new_state_dict = {}\n    for key in global_model.state_dict().keys():\n        new_state_dict[key] = torch.zeros_like(global_model.state_dict()[key])\n        for i, size in enumerate(client_sizes):\n            new_state_dict[key] += (size / total_size) * client_models[i].state_dict()[key]\n    global_model.load_state_dict(new_state_dict)\n\n# ----------------------------------------------------------------------\n## ðŸ’» Data Preparation Utilities (for Non-IID Sharding)\n# ----------------------------------------------------------------------\ndef clean_df(df, max_ds_len=300, max_code_len=800):\n    \"\"\"Keep only rows with non-null, reasonably short docstring & code.\"\"\"\n    df = df[['docstring', 'code', 'path']].dropna()\n    df = df[df['docstring'].str.len() < max_ds_len]\n    df = df[df['code'].str.len() < max_code_len]\n    return df.reset_index(drop=True)\n\ndef shard_by_owner(df, K):\n    \"\"\"\n    Simulate K clients by grouping functions by 'owner' (first part of path).\n    Returns a list of K DataFrames, each a heterogeneous shard.\n    \"\"\"\n    df['owner'] = df['path'].apply(lambda p: os.path.normpath(p).split(os.sep)[0])\n    owners = df['owner'].unique().tolist()\n    np.random.shuffle(owners)\n    shards = defaultdict(list)\n    for idx, owner in enumerate(owners):\n        shard_id = idx % K\n        shards[shard_id].append(owner)\n    shard_dfs = []\n    for k in range(K):\n        owners_k = shards[k]\n        df_k = df[df['owner'].isin(owners_k)].drop(columns=['owner'])\n        shard_dfs.append(df_k.reset_index(drop=True))\n    return shard_dfs\n\ndef load_and_preprocess(lang_dir, K=5, val_frac=0.05, random_state=42, percentage=1.0):\n    \"\"\"\n    Load and preprocess CodeSearchNet data for one language.\n    \"\"\"\n    assert 0 < percentage <= 1.0, \"percentage must be in (0, 1]\"\n    train_files = glob.glob(os.path.join(lang_dir, 'final/jsonl/train/*.jsonl'))\n    test_files = glob.glob(os.path.join(lang_dir, 'final/jsonl/test/*.jsonl'))\n    train_df = pd.concat([pd.read_json(f, lines=True) for f in train_files], ignore_index=True)\n    test_df = pd.concat([pd.read_json(f, lines=True) for f in test_files], ignore_index=True)\n    if percentage < 1.0:\n        train_df = train_df.sample(frac=percentage, random_state=random_state).reset_index(drop=True)\n        test_df = test_df.sample(frac=percentage, random_state=random_state).reset_index(drop=True)\n    train_df = clean_df(train_df)\n    test_df = clean_df(test_df)\n    train_df, public_val = train_test_split(\n        train_df, test_size=val_frac, random_state=random_state, shuffle=True\n    )\n    client_shards = shard_by_owner(train_df, K)\n    return {\n        'clients': client_shards,\n        'public_val': public_val,\n        'test': test_df\n    }\n\ndef prepare_all_languages(base_dir, languages, K=5, percentage=1.0):\n    \"\"\"\n    Iterate over each language directory, preprocess, and collect.\n    \"\"\"\n    all_data = {}\n    for lang in languages:\n        lang_path = os.path.join(base_dir, lang, lang)\n        if not os.path.isdir(lang_path):\n            print(f\"âš ï¸ Skipping '{lang_path}' â€“ directory not found.\")\n            continue\n        print(f\"â³ Preprocessing {lang}...\")\n        all_data[lang] = load_and_preprocess(lang_path, K=K, percentage=percentage)\n        print(f\"âœ… Done: {lang} -> {len(all_data[lang]['clients'])} shards ({sum(len(df) for df in all_data[lang]['clients'])} total samples).\")\n    return all_data\n\ndef flatten_client_shards(federated_data):\n    \"\"\"\n    Combines the client lists from all languages into a single list of client DataFrames.\n    \"\"\"\n    all_clients = []\n    for lang, data in federated_data.items():\n        all_clients.extend(data['clients'])\n    return all_clients\n\n# ----------------------------------------------------------------------\n## ðŸš€ Main Training Script\n# ----------------------------------------------------------------------\n# Hyperparameters\nNUM_EXPERTS = 8\nTOP_K = 2\nPROJ_DIM = 128\nBATCH_SIZE = 16\nLOCAL_STEPS = 1\nLEARNING_RATE = 1e-5\nCLIP_NORM = 1.0\nNOISE_STD = 0.01\nNUM_ROUNDS = 2\nLANGUAGES = ['python', 'java', 'go']\nLOAD_BALANCE_COEFF = 0.01\nNUM_CLIENTS_PER_LANG = 1  # K\nDATA_LOAD_PERCENTAGE = 0.001 # <--- Set to 0.001 for a rapid test (0.1% or 1/1000th)\n\n# Main training script\nif __name__ == \"__main__\":\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n    global_model = FedMoECR(NUM_EXPERTS, TOP_K, PROJ_DIM, LOAD_BALANCE_COEFF).to(device)\n    ## ðŸŒ Data Loading & Sharding Logic\n    print(\"\\n--- Starting Federated Data Preparation ---\")\n    BASE_DIR = \"/kaggle/input/codesearchnet\"\n    federated_data = prepare_all_languages(BASE_DIR, LANGUAGES, K=NUM_CLIENTS_PER_LANG, percentage=DATA_LOAD_PERCENTAGE)\n    all_client_dataframes = flatten_client_shards(federated_data)\n    print(f\"Total number of clients for FL: {len(all_client_dataframes)}\\n\")\n    client_dataloaders = []\n    client_sizes = []\n    for df in all_client_dataframes:\n        if len(df) > 0:\n            code_ds = CodeDataset(df)\n            client_sizes.append(len(code_ds))\n            dl = DataLoader(code_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda b: collate_fn(b, tokenizer))\n            client_dataloaders.append(dl)\n        else:\n            print(\"Skipped an empty client shard.\")\n    ## ðŸš€ START TRAINING\n    print(\"--- Starting Federated Training Rounds ---\")\n    for round_num in range(NUM_ROUNDS):\n        print(f\"Round {round_num + 1}/{NUM_ROUNDS}\")\n        client_models = []\n        for dl in client_dataloaders:\n            client_model = FedMoECR(NUM_EXPERTS, TOP_K, PROJ_DIM, LOAD_BALANCE_COEFF).to(device)\n            client_model.load_state_dict(global_model.state_dict())\n            optimizer = optim.Adam(client_model.parameters(), lr=LEARNING_RATE)\n            local_update(client_model, dl, optimizer, device, LOCAL_STEPS, CLIP_NORM, NOISE_STD)\n            client_models.append(client_model)\n        federated_aggregation(global_model, client_models, client_sizes)\n    torch.save(global_model.state_dict(), \"fedmoe_cr_model.pth\")\n    # Example Inference\n    def infer_code_recommendation(model, tokenizer, query, candidate_codes, device, top_k=5):\n        model.eval()\n        with torch.no_grad():\n            q_inputs = tokenizer(query, return_tensors='pt', truncation=True, max_length=128).to(device)\n            z_q = model(q_inputs)\n            z_cs = []\n            for code in candidate_codes:\n                c_inputs = tokenizer(code, return_tensors='pt', truncation=True, max_length=512).to(device)\n                z_c = model(c_inputs)\n                z_cs.append(z_c)\n            z_cs = torch.cat(z_cs, dim=0)\n            scores = F.cosine_similarity(z_q, z_cs)\n            top_indices = scores.topk(top_k).indices\n            return [candidate_codes[i] for i in top_indices]\n    query = \"Sort a list in Python\"\n    candidates = [\"def sort_list(l): return sorted(l)\", \"l.sort()\", \"import numpy as np; np.sort(l)\", \"random code\"]\n    recommendations = infer_code_recommendation(global_model, tokenizer, query, candidates, device)\n    print(\"\\nTop recommendations:\", recommendations)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:06:56.128520Z","iopub.execute_input":"2025-12-04T05:06:56.129151Z","iopub.status.idle":"2025-12-04T05:10:25.824278Z","shell.execute_reply.started":"2025-12-04T05:06:56.129123Z","shell.execute_reply":"2025-12-04T05:10:25.823212Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbbc8b55f29b425bbce6d0c8ffcdd9e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b1f895ff5b94a0ab4bca987eb267d62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b412f56e7cfc4fd6a28d56f400e26c85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5df8796e05422ebc0db551d4baabea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7945783d306e439bbaab87074aa51330"}},"metadata":{}},{"name":"stderr","text":"2025-12-04 05:07:17.780737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764824838.038429      38 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764824838.108538      38 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3a27bd3905942f5b40d59cc848d887b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b75998ffa2a8443a83c07f0baa1e946e"}},"metadata":{}},{"name":"stdout","text":"\n--- Starting Federated Data Preparation ---\nâ³ Preprocessing python...\nâœ… Done: python -> 1 shards (209 total samples).\nâ³ Preprocessing java...\nâœ… Done: java -> 1 shards (244 total samples).\nâ³ Preprocessing go...\nâœ… Done: go -> 1 shards (245 total samples).\nTotal number of clients for FL: 3\n\n--- Starting Federated Training Rounds ---\nRound 1/2\nRound 2/2\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/1836075136.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Sort a list in Python\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"def sort_list(l): return sorted(l)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"l.sort()\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"import numpy as np; np.sort(l)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m     \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_code_recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTop recommendations:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/1836075136.py\u001b[0m in \u001b[0;36minfer_code_recommendation\u001b[0;34m(model, tokenizer, query, candidate_codes, device, top_k)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mz_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_cs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0mtop_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcandidate_codes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Sort a list in Python\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"],"ename":"RuntimeError","evalue":"selected index k out of range","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"query = \"Sort a list in Python\"\ncandidates = [\n    \"def sort_list(l): return sorted(l)\",\n    \"l.sort()\",\n    \"import numpy as np; np.sort(l)\",\n    \"random code\",\n    \"another random code block\" # <--- Added 5th candidate\n]\nrecommendations = infer_code_recommendation(global_model, tokenizer, query, candidates, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:14:07.797664Z","iopub.execute_input":"2025-12-04T05:14:07.798183Z","iopub.status.idle":"2025-12-04T05:14:07.872679Z","shell.execute_reply.started":"2025-12-04T05:14:07.798163Z","shell.execute_reply":"2025-12-04T05:14:07.872000Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(\"\\nTop recommendations:\", recommendations)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:14:23.815991Z","iopub.execute_input":"2025-12-04T05:14:23.816695Z","iopub.status.idle":"2025-12-04T05:14:23.820646Z","shell.execute_reply.started":"2025-12-04T05:14:23.816669Z","shell.execute_reply":"2025-12-04T05:14:23.819908Z"}},"outputs":[{"name":"stdout","text":"\nTop recommendations: ['another random code block', 'l.sort()', 'random code', 'import numpy as np; np.sort(l)', 'def sort_list(l): return sorted(l)']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModel, AutoTokenizer\nfrom datasets import load_dataset\nimport copy\nimport types\nimport weakref\nimport os\nimport glob\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nimport math\nimport matplotlib.pyplot as plt # <--- NEW: Import for plotting\n# --- END: Data Utilities Imports ---\n\n# ----------------------------------------------------------------------\n## ðŸ“Š NEW: MoE Diagnostics Class\n# ----------------------------------------------------------------------\nclass MoEDiagnostics:\n    \"\"\"Stores and accumulates expert dispatch statistics across a forward pass.\"\"\"\n    def __init__(self, num_experts, num_layers):\n        self.num_experts = num_experts\n        self.num_layers = num_layers\n        self.reset()\n\n    def reset(self):\n        # Accumulated dispatch fraction for each expert across all MoE layers\n        self.expert_dispatch_sum = torch.zeros(self.num_layers, self.num_experts)\n        self.sample_count = 0\n\n    def record(self, layer_idx, dispatch_fraction):\n        \"\"\"Records the dispatch fraction (load) for a single layer/batch.\"\"\"\n        self.expert_dispatch_sum[layer_idx] += dispatch_fraction.cpu()\n        \n    def get_avg_dispatch(self):\n        \"\"\"Calculates the average dispatch fraction per expert.\"\"\"\n        # Note: If called after a full forward pass, sample_count should be updated externally\n        if self.sample_count == 0:\n            return torch.zeros(self.num_layers, self.num_experts)\n        return self.expert_dispatch_sum / self.sample_count\n\n\nclass MoEFFN(nn.Module):\n    \"\"\"\n    Mixture-of-Experts Feed-Forward Network replacing the standard FFN in transformer layers.\n    Supports load balancing loss and records dispatch diagnostics.\n    \"\"\"\n    def __init__(self, config, num_experts=8, top_k=2, load_balance_coeff=0.01, layer_idx=None): # <--- NEW: layer_idx\n        super().__init__()\n        self.hidden_size = config.hidden_size\n        self.intermediate_size = config.intermediate_size\n        self.gate = nn.Linear(self.hidden_size, num_experts)\n        self.experts = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(self.hidden_size, self.intermediate_size),\n                nn.GELU(),\n                nn.Linear(self.intermediate_size, self.hidden_size)\n            ) for _ in range(num_experts)\n        ])\n        self.top_k = top_k\n        self.num_experts = num_experts\n        self.load_balance_coeff = load_balance_coeff\n        self.layer_idx = layer_idx # <--- NEW: Store layer index for diagnostics\n        self.parent_diagnostics = None # <--- NEW: Placeholder for Diagnostics object\n\n    def forward(self, hidden_states):\n        batch_size, seq_len, hidden_size = hidden_states.shape\n        flat_hidden = hidden_states.reshape(-1, hidden_size)  # (b*s, d)\n        num_tokens = flat_hidden.shape[0]\n        gate_logits = self.gate(flat_hidden)  # (b*s, e)\n        gate_probs = torch.softmax(gate_logits, dim=-1)\n        topk_probs, topk_idx = gate_probs.topk(self.top_k, dim=-1)  # (b*s, k)\n        final_output = torch.zeros_like(flat_hidden)\n        balance_loss = torch.zeros((), device=hidden_states.device)\n        \n        # --- NEW: Dispatch tracking initialization ---\n        dispatch_fraction = None\n        router_prob_mean = None\n        if self.training or (self.parent_diagnostics is not None and not self.training):\n            dispatch_fraction = torch.zeros(self.num_experts, device=hidden_states.device)\n            router_prob_mean = gate_probs.mean(dim=0)\n        # ---------------------------------------------\n\n        for e in range(self.num_experts):\n            expert_mask = (topk_idx == e)\n            token_mask = expert_mask.any(dim=-1)\n            flat_token_indices = torch.nonzero(token_mask).squeeze(-1)\n            if flat_token_indices.numel() == 0:\n                continue\n            input_e = flat_hidden.index_select(0, flat_token_indices)\n            out_e = self.experts[e](input_e)\n            probs_for_e = (topk_probs * expert_mask.float()).sum(dim=-1)\n            weights = probs_for_e[token_mask]\n            weighted = out_e * weights.unsqueeze(-1)\n            final_output.index_add_(0, flat_token_indices, weighted)\n            \n            if dispatch_fraction is not None:\n                dispatch_fraction[e] = token_mask.float().sum() / num_tokens\n        \n        # --- NEW: Record diagnostics on both train and eval ---\n        if self.parent_diagnostics is not None and dispatch_fraction is not None:\n            self.parent_diagnostics.record(self.layer_idx, dispatch_fraction)\n        # ----------------------------------------------------\n        \n        if self.training:\n            if dispatch_fraction is not None and router_prob_mean is not None:\n                balance_loss = self.load_balance_coeff * self.num_experts * (dispatch_fraction * router_prob_mean).sum()\n        \n        return final_output.reshape(batch_size, seq_len, hidden_size), balance_loss\n\nclass Projection(nn.Module):\n    # ... (Projection class remains unchanged)\n    # ...\n    def __init__(self, in_dim, hidden_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hidden_dim)\n        self.act = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, out_dim)\n\n    def forward(self, h):\n        return self.fc2(self.act(self.fc1(h)))\n\n\nclass FedMoECR(nn.Module):\n    \"\"\"\n    FedMoE-CR model: CodeBERT backbone with MoE layers and projection head.\n    \"\"\"\n    def __init__(self, num_experts=8, top_k=2, proj_dim=128, load_balance_coeff=0.01):\n        super().__init__()\n        self.encoder = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n        dim = self.encoder.config.hidden_size\n        self.projection = Projection(dim, dim * 4, proj_dim)\n        self.log_tau = nn.Parameter(torch.tensor(math.log(0.07)))\n        self.total_balance_loss = torch.tensor(0.0)\n        \n        # --- NEW: MoE Layer Indices & Diagnostics Setup ---\n        self.moe_layer_indices = [5, 8] # Layers 6 and 9\n        self.diagnostics = MoEDiagnostics(num_experts, len(self.moe_layer_indices)) # <--- NEW: Diagnostics object\n        # ---------------------------------------------------\n        \n        # Replace two mid-layer FFN blocks with MoE\n        for moe_idx, i in enumerate(self.moe_layer_indices): # <--- NEW: Enumerate for layer index\n            layer = self.encoder.encoder.layer[i]\n            # 1. Attach MoE FFN and Parent Reference\n            moe_ffn = MoEFFN(self.encoder.config, num_experts, top_k, load_balance_coeff, layer_idx=moe_idx) # <--- Pass moe_idx\n            moe_ffn.parent_diagnostics = self.diagnostics # <--- NEW: Link diagnostics object\n            layer.moe_ffn = moe_ffn\n            # CRITICAL FIX: Use weakref to store parent reference without module registration\n            layer.parent_model = weakref.ref(self)\n            # 2. Set up LayerNorm aliases (CodeBERT structure)\n            layer.layernorm_before = layer.attention.output.LayerNorm\n            layer.layernorm_after = layer.output.LayerNorm\n\n            # ... (new_forward remains the same)\n            def new_forward(layer_self, hidden_states, attention_mask=None, head_mask=None,\n                            encoder_hidden_states=None, encoder_attention_mask=None,\n                            past_key_value=None, output_attentions=False):\n                # 1. Self-Attention Block\n                self_attention_outputs = layer_self.attention(\n                    hidden_states, attention_mask, head_mask, output_attentions=output_attentions,\n                )\n                attention_output = self_attention_outputs[0]\n                outputs = self_attention_outputs[1:]\n                # No extra residual/LN here; attention_output is already post-residual + LN\n                normalized_attention_output = attention_output\n                # 3. MoE Feed-Forward Network\n                moe_output, moe_balance_loss = layer_self.moe_ffn(normalized_attention_output)\n                # 4. Second Residual Connection + LayerNorm (Post-MoE)\n                moe_output = layer_self.output.dropout(moe_output)\n                layer_output = layer_self.layernorm_after(moe_output + normalized_attention_output)\n                # 5. Accumulate Loss\n                if layer_self.training:\n                    # CRITICAL FIX: Dereference weakref and check if parent is alive\n                    parent = layer_self.parent_model()\n                    if parent is not None:\n                        parent.total_balance_loss += moe_balance_loss\n                outputs = (layer_output,) + outputs\n                return outputs\n\n            # 3. Bind the new forward method\n            layer.forward = types.MethodType(new_forward, layer)\n\n    def forward(self, inputs):\n        # Reset sample count here for diagnostics accumulation\n        if not self.training:\n             self.diagnostics.sample_count = 0\n             self.diagnostics.expert_dispatch_sum = torch.zeros(self.diagnostics.num_layers, self.diagnostics.num_experts)\n\n        outputs = self.encoder(**inputs)\n        \n        # Increment sample count for diagnostics\n        if not self.training:\n            # Assuming batch size is the first dimension of input_ids\n            batch_size = inputs['input_ids'].shape[0]\n            self.diagnostics.sample_count += batch_size\n        \n        h = outputs.last_hidden_state[:, 0]  # CLS token\n        z = self.projection(h)\n        z = F.normalize(z, dim=1)\n        return z\n\n# ... (CodeDataset, collate_fn, compute_loss, apply_dp_gradients, local_update, federated_aggregation remain mostly unchanged) ...\n\n\n# ----------------------------------------------------------------------\n## ðŸ“Š NEW: Evaluation and Graph Functions\n# ----------------------------------------------------------------------\n\ndef calculate_metrics(z_q, z_c, device, top_ks=[1, 5, 10]):\n    \"\"\"Calculates R@K and MRR for a batch.\"\"\"\n    dots = torch.mm(z_q, z_c.T)\n    # The correct code is on the diagonal\n    labels = torch.arange(z_q.size(0)).to(device)\n    \n    # Sort by similarity score in descending order\n    _, sorted_indices = dots.sort(dim=1, descending=True)\n    \n    # Calculate Rank and MRR\n    # Find the position of the correct label in the sorted list (rank is 1-indexed)\n    correct_ranks = (sorted_indices == labels.unsqueeze(1)).nonzero(as_tuple=True)[1] + 1\n    mrr = (1.0 / correct_ranks.float()).sum().item()\n    \n    # Calculate Recall@K\n    recall = {}\n    for k in top_ks:\n        # Check if the correct rank is less than or equal to k\n        hits_at_k = (correct_ranks <= k).sum().item()\n        recall[f'R@{k}'] = hits_at_k\n\n    return mrr, recall\n\n\ndef evaluate_model(model, df_test, tokenizer, device, top_ks=[1, 5, 10]):\n    \"\"\"Evaluates the global model on the aggregated test set.\"\"\"\n    model.eval()\n    test_ds = CodeDataset(df_test)\n    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda b: collate_fn(b, tokenizer))\n\n    total_mrr = 0\n    total_samples = 0\n    total_recall = {f'R@{k}': 0 for k in top_ks}\n\n    with torch.no_grad():\n        for q_inputs, c_inputs in test_dl:\n            q_inputs = {k: v.to(device) for k, v in q_inputs.items()}\n            c_inputs = {k: v.to(device) for k, v in c_inputs.items()}\n            \n            z_q = model(q_inputs)\n            z_c = model(c_inputs)\n            \n            mrr, recall = calculate_metrics(z_q, z_c, device, top_ks)\n            \n            batch_size = z_q.size(0)\n            total_mrr += mrr\n            for k in top_ks:\n                total_recall[f'R@{k}'] += recall[f'R@{k}']\n            total_samples += batch_size\n    \n    avg_mrr = total_mrr / total_samples\n    avg_recall = {k: v / total_samples for k, v in total_recall.items()}\n    \n    # After evaluation, calculate and return average expert dispatch\n    avg_dispatch = model.diagnostics.get_avg_dispatch()\n\n    return avg_mrr, avg_recall, avg_dispatch\n\n\ndef plot_expert_load_distribution(avg_dispatch, round_num, moe_layer_indices):\n    \"\"\"Plots the average dispatch fraction for all experts in all layers.\"\"\"\n    num_layers, num_experts = avg_dispatch.shape\n    fig, axes = plt.subplots(1, num_layers, figsize=(num_experts * 2.5, 5), sharey=True)\n    \n    if num_layers == 1: # Handle case with only one layer\n        axes = [axes]\n\n    for i in range(num_layers):\n        ax = axes[i]\n        dispatch_data = avg_dispatch[i].numpy()\n        ax.bar(range(num_experts), dispatch_data)\n        ax.axhline(y=TOP_K / num_experts, color='r', linestyle='--', label=f'Target Load ({TOP_K}/{num_experts})')\n        ax.set_title(f'MoE Layer {moe_layer_indices[i]}')\n        ax.set_xticks(range(num_experts))\n        ax.set_xlabel('Expert ID')\n        ax.grid(axis='y', alpha=0.5)\n        \n    axes[0].set_ylabel('Average Dispatch Fraction')\n    fig.suptitle(f'Expert Load Distribution (Round {round_num})')\n    plt.tight_layout(rect=[0, 0, 1, 0.96])\n    # Placeholder for saving/displaying the plot\n    plt.savefig(f'expert_load_round_{round_num}.png')\n    plt.close()\n    print(f\"Graph saved: expert_load_round_{round_num}.png \")\n\n\ndef plot_training_curve(results):\n    \"\"\"Plots the R@1 score over training rounds.\"\"\"\n    rounds = [r['round'] for r in results]\n    r1_scores = [r['R@1'] * 100 for r in results] # Convert to percentage\n    \n    plt.figure(figsize=(10, 6))\n    plt.plot(rounds, r1_scores, marker='o', label='Global Model R@1')\n    plt.xlabel('Federated Round')\n    plt.ylabel('Recall@1 (%)')\n    plt.title('Code Recommendation Performance over FL Rounds')\n    plt.grid(True)\n    plt.legend()\n    # Placeholder for saving/displaying the plot\n    plt.savefig('performance_curve.png')\n    plt.close()\n    print(\"Graph saved: performance_curve.png \")\n\n# ----------------------------------------------------------------------\n## ðŸš€ Main Training Script (UPDATED)\n# ----------------------------------------------------------------------\n# Hyperparameters\nNUM_EXPERTS = 8\nTOP_K = 2\nPROJ_DIM = 128\nBATCH_SIZE = 16\nLOCAL_STEPS = 1\nLEARNING_RATE = 1e-5\nCLIP_NORM = 1.0\nNOISE_STD = 0.01\nNUM_ROUNDS = 2 # Increase this for real research\nLANGUAGES = ['python', 'java', 'go']\nLOAD_BALANCE_COEFF = 0.01\nNUM_CLIENTS_PER_LANG = 1\nDATA_LOAD_PERCENTAGE = 0.001 \n\n# Global results storage for plotting\nGLOBAL_RESULTS = []\n\nif __name__ == \"__main__\":\n    # ... (Initialization code remains the same) ...\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n    global_model = FedMoECR(NUM_EXPERTS, TOP_K, PROJ_DIM, LOAD_BALANCE_COEFF).to(device)\n    \n    ## ðŸŒ Data Loading & Sharding Logic\n    print(\"\\n--- Starting Federated Data Preparation ---\")\n    BASE_DIR = \"/kaggle/input/codesearchnet\"\n    federated_data = prepare_all_languages(BASE_DIR, LANGUAGES, K=NUM_CLIENTS_PER_LANG, percentage=DATA_LOAD_PERCENTAGE)\n    all_client_dataframes = flatten_client_shards(federated_data)\n    \n    # Combine all test sets for global evaluation (This is crucial)\n    aggregated_test_df = pd.concat([data['test'] for data in federated_data.values()], ignore_index=True)\n    print(f\"Total test samples for evaluation: {len(aggregated_test_df)}\")\n\n    print(f\"Total number of clients for FL: {len(all_client_dataframes)}\\n\")\n    client_dataloaders = []\n    client_sizes = []\n    for df in all_client_dataframes:\n        if len(df) > 0:\n            code_ds = CodeDataset(df)\n            client_sizes.append(len(code_ds))\n            dl = DataLoader(code_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda b: collate_fn(b, tokenizer))\n            client_dataloaders.append(dl)\n        else:\n            print(\"Skipped an empty client shard.\")\n\n    ## ðŸš€ START TRAINING\n    print(\"--- Starting Federated Training Rounds ---\")\n    for round_num in range(NUM_ROUNDS):\n        print(f\"Round {round_num + 1}/{NUM_ROUNDS}\")\n        client_models = []\n        \n        # 1. Local Training\n        for dl in client_dataloaders:\n            # IMPORTANT: Re-initialize FedMoECR to ensure MoE_FFN is correctly linked to diagnostics\n            client_model = FedMoECR(NUM_EXPERTS, TOP_K, PROJ_DIM, LOAD_BALANCE_COEFF).to(device)\n            client_model.load_state_dict(global_model.state_dict())\n            optimizer = optim.Adam(client_model.parameters(), lr=LEARNING_RATE)\n            local_update(client_model, dl, optimizer, device, LOCAL_STEPS, CLIP_NORM, NOISE_STD)\n            client_models.append(client_model)\n            \n        # 2. Aggregation\n        federated_aggregation(global_model, client_models, client_sizes)\n        \n        # 3. Global Evaluation and Diagnostics (REQUIRED FOR GRAPHS)\n        avg_mrr, avg_recall, avg_dispatch = evaluate_model(global_model, aggregated_test_df, tokenizer, device, top_ks=[1, 5, 10])\n        \n        print(f\"--- Evaluation Round {round_num + 1} ---\")\n        print(f\"MRR: {avg_mrr:.4f} | R@1: {avg_recall['R@1']:.4f} | R@5: {avg_recall['R@5']:.4f}\")\n        \n        # Store results for plotting the learning curve\n        GLOBAL_RESULTS.append({\n            'round': round_num + 1,\n            'MRR': avg_mrr,\n            'R@1': avg_recall['R@1'],\n            'avg_dispatch': avg_dispatch # Store for later analysis if needed\n        })\n        \n        # Plot the expert load distribution (MoE Diagnostic Graph)\n        plot_expert_load_distribution(avg_dispatch, round_num + 1, global_model.moe_layer_indices)\n\n    # 4. Final steps\n    torch.save(global_model.state_dict(), \"fedmoe_cr_model.pth\")\n    \n    # Plot the final performance curve\n    plot_training_curve(GLOBAL_RESULTS)\n    \n    # Example Inference (keep this for code completion)\n    # ... (infer_code_recommendation function call remains the same) ...\n    def infer_code_recommendation(model, tokenizer, query, candidate_codes, device, top_k=5):\n        model.eval()\n        with torch.no_grad():\n            q_inputs = tokenizer(query, return_tensors='pt', truncation=True, max_length=128).to(device)\n            z_q = model(q_inputs)\n            z_cs = []\n            for code in candidate_codes:\n                c_inputs = tokenizer(code, return_tensors='pt', truncation=True, max_length=512).to(device)\n                z_c = model(c_inputs)\n                z_cs.append(z_c)\n            z_cs = torch.cat(z_cs, dim=0)\n            scores = F.cosine_similarity(z_q, z_cs)\n            top_indices = scores.topk(top_k).indices\n            return [candidate_codes[i] for i in top_indices]\n    \n    query = \"Sort a list in Python\"\n    candidates = [\"def sort_list(l): return sorted(l)\", \"l.sort()\", \"import numpy as np; np.sort(l)\", \"random code\", \"another code\"] # Added a fifth candidate\n    recommendations = infer_code_recommendation(global_model, tokenizer, query, candidates, device, top_k=4) # Adjusted top_k\n    print(\"\\nTop recommendations:\", recommendations)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:28:54.598822Z","iopub.execute_input":"2025-12-04T06:28:54.599347Z","iopub.status.idle":"2025-12-04T06:31:24.556180Z","shell.execute_reply.started":"2025-12-04T06:28:54.599315Z","shell.execute_reply":"2025-12-04T06:31:24.555416Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Federated Data Preparation ---\nâ³ Preprocessing python...\nâœ… Done: python -> 1 shards (209 total samples).\nâ³ Preprocessing java...\nâœ… Done: java -> 1 shards (244 total samples).\nâ³ Preprocessing go...\nâœ… Done: go -> 1 shards (245 total samples).\nTotal test samples for evaluation: 42\nTotal number of clients for FL: 3\n\n--- Starting Federated Training Rounds ---\nRound 1/2\n--- Evaluation Round 1 ---\nMRR: 0.3023 | R@1: 0.1429 | R@5: 0.4524\nGraph saved: expert_load_round_1.png \nRound 2/2\n--- Evaluation Round 2 ---\nMRR: 0.3311 | R@1: 0.1667 | R@5: 0.4524\nGraph saved: expert_load_round_2.png \nGraph saved: performance_curve.png \n\nTop recommendations: ['l.sort()', 'another code', 'random code', 'def sort_list(l): return sorted(l)']\n","output_type":"stream"}],"execution_count":10}]}